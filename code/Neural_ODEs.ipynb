{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural ODEs\n",
    "Red Neuronal para simulacion de EDOs de primer ordel del tipo\n",
    "$$\\dfrac{d}{dt}S(t)=P_1(t) + P_2(t)*P_3(S)$$\n",
    "donde $P_1$, $P_2$ y $P_3$ son polinomios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Recarga los modulos\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lucifer                                2022-12-02 19:21:59  526.98\n",
      "[0] NVIDIA GeForce RTX 3080 Laptop GPU | 52Â°C,   0 % |  1331 /  8192 MB | LUCIFER\\Det-Pc(?M) LUCIFER\\Det-Pc(?M)\n"
     ]
    }
   ],
   "source": [
    "import gpustat\n",
    "gpustat.print_gpustat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as mp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data as data_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from api.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tamano de los datos de polinomio en S y t es: 0\n",
      "El tamano de los datos de polinomio en S es    : 0\n",
      "El tamano de los datos de polinomio en t es    : 0\n",
      "El numero total de los datos es                : 999993\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos datos de las simulaciones\n",
    "file_name = 'datos_ODEs_cos_100.csv'\n",
    "dir_file = 'C:/Users/Det-Pc/OneDrive/Documentos/GitHub/Proyecto_curso_DL/data'\n",
    "data = get_ode_data(dir_file + '/' + file_name)\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>funcion</th>\n",
       "      <th>grade_f _t</th>\n",
       "      <th>grade_f_s</th>\n",
       "      <th>I_c</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>int_0</th>\n",
       "      <th>int_f</th>\n",
       "      <th>sol.t</th>\n",
       "      <th>sol.y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cos_s_t</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010087</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...</td>\n",
       "      <td>[0.010087274744655872, 0.010163938257431315, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cos_s_t</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.462783</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...</td>\n",
       "      <td>[1.4627829216984938, 1.4627793823005937, 1.462...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cos_s_t</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.617596</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...</td>\n",
       "      <td>[1.6175964330144468, 1.6345681291574026, 1.651...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cos_s_t</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.537306</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...</td>\n",
       "      <td>[-0.5373064398304225, -0.5373251786954568, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cos_s_t</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.683805</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...</td>\n",
       "      <td>[-0.6838045572046187, -0.6693757742090535, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   funcion  grade_f _t  grade_f_s       I_c  n_steps  int_0  int_f  \\\n",
       "0  cos_s_t           0          0  0.010087      100      0      1   \n",
       "1  cos_s_t           0          0  1.462783      100      0      1   \n",
       "2  cos_s_t           0          0  1.617596      100      0      1   \n",
       "3  cos_s_t           0          0 -0.537306      100      0      1   \n",
       "4  cos_s_t           0          0 -0.683805      100      0      1   \n",
       "\n",
       "                                               sol.t  \\\n",
       "0  [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...   \n",
       "1  [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...   \n",
       "2  [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...   \n",
       "3  [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...   \n",
       "4  [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...   \n",
       "\n",
       "                                               sol.y  \n",
       "0  [0.010087274744655872, 0.010163938257431315, 0...  \n",
       "1  [1.4627829216984938, 1.4627793823005937, 1.462...  \n",
       "2  [1.6175964330144468, 1.6345681291574026, 1.651...  \n",
       "3  [-0.5373064398304225, -0.5373251786954568, -0....  \n",
       "4  [-0.6838045572046187, -0.6693757742090535, -0....  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraemos los valores de las simulaciones\n",
    "df_values = data['sol.y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 75\n",
    "size_predic = len(data['sol.y'].values[0])\n",
    "len_sim = df_values.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos las sucesiones con los datos estandarizados\n",
    "X_data, Y_data = get_seqs(data=df_values, seq_len=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EL tamano de los datos las sucesiones_X es: (999918, 75)\n",
      "EL tamano de los datos las sucesiones_Y es: (999918, 25)\n"
     ]
    }
   ],
   "source": [
    "print(f'EL tamano de los datos las sucesiones_X es: {X_data.shape}')\n",
    "print(f'EL tamano de los datos las sucesiones_Y es: {Y_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# porcentaje de datos de entrenamiento\n",
    "pct_data_train = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_data = list(range(X_data.shape[0]))\n",
    "\n",
    "train_index = random.sample(index_data, int(len(index_data)*pct_data_train))\n",
    "val_test_index = list(set(index_data)-set(train_index))\n",
    "val_index = random.sample(val_test_index, int(len(val_test_index)*0.5))\n",
    "test_index = list(set(val_test_index)-set(val_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos las particiones\n",
    "data_dic = {'train':X_data[train_index],\\\n",
    "           'val':X_data[val_index],\\\n",
    "           'test':X_data[test_index]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EDOs_dataloader(data_torch.Dataset):\n",
    "    def __init__(self, edos_s):\n",
    "        self.edos_s = edos_s\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        edo_i = self.edos_s[index]\n",
    "        return edo_i\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.edos_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se cargo la data exitosamente!\n",
      "El tamano de la dataset es {'train': 799934, 'val': 99992, 'test': 99992}\n"
     ]
    }
   ],
   "source": [
    "partitions = ['train', 'val', 'test']\n",
    "batch_size = {'train': 512, 'val':256, 'test':1}\n",
    "shuffle = True\n",
    "lr = 0.001\n",
    "edos_datasets = {x: EDOs_dataloader(data_dic[x]) for x in partitions}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(edos_datasets[x], batch_size=batch_size[x], shuffle=shuffle) for x in partitions}\n",
    "dataset_sizes = {x: len(edos_datasets[x]) for x in partitions}\n",
    "print('Se cargo la data exitosamente!')\n",
    "print(f'El tamano de la dataset es {dataset_sizes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estamos usando: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Estamos usando: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class TimeDistributed(nn.Module):\n",
    "    def __init__(self, module, batch_first=True):\n",
    "        # def __init__(self, module, batch_first=False):\n",
    "        super(TimeDistributed, self).__init__()\n",
    "        self.module = module\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if len(x.size()) <= 2:\n",
    "            return self.module(x)\n",
    "\n",
    "        # concatena samples y timesteps en un solo vector\n",
    "        x_reshape = x.contiguous().view(-1, x.size(-1))  # (samples * timesteps, input_size)\n",
    "\n",
    "        y = self.module(x_reshape)\n",
    "\n",
    "        # We have to reshape Y\n",
    "        if self.batch_first:\n",
    "            y = y.contiguous().view(x.size(0), -1, y.size(-1))  # (samples, timesteps, output_size)\n",
    "        else:\n",
    "            y = y.view(-1, x.size(1), y.size(-1))  # (timesteps, samples, output_size)\n",
    "\n",
    "        return y\n",
    "\n",
    "class ODE_NET(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(ODE_NET, self).__init__()\n",
    "        # self.hidden_dim = hidden_dim\n",
    "        self.conv1 = nn.Conv1d(in_channels=1,out_channels=32,kernel_size=6,stride=2,padding=3)\n",
    "        self.relu = nn.ReLU()\n",
    "        # self.pool = nn.MaxPool1d(2, 2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=32,out_channels=16,kernel_size=6,stride=2,padding=3)\n",
    "        # self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        # self.fc2 = nn.Linear(120, 84)\n",
    "        # self.fc3 = nn.Linear(84, 10)\n",
    "        self.rnn1 = nn.LSTM(input_size=640, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.linear = nn.Linear(64, size_predic-seq_len)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        print(x.shape)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        print(x.shape)\n",
    "        x = x.view(-1,)\n",
    "        print(x.shape[0])\n",
    "        x, hidden = self.rnn1(x, hidden)\n",
    "        x = x.contiguous().view(-1, self.hidden_dim)\n",
    "        # x = F.relu(self.fc1(x))\n",
    "        # x = F.relu(self.fc2(x))\n",
    "        x = self.linear(x)\n",
    "        return x, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "                    weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
    "        return hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_S(nn.Module):\n",
    "    def __init__(self, seq_len):\n",
    "        super(Model_S, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        # self.flatten = nn.Flatten()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=12, kernel_size=6, stride=2, padding=3)\n",
    "        self.pool1 = nn.MaxPool1d(2, 2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=26, out_channels=14, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool1d(2, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print('El tamano de la entrada es: ', x.shape)\n",
    "        # El tamano de la entrada es:  torch.Size([2, 1, 75])\n",
    "\n",
    "        # x = self.flatten(x)\n",
    "        # print('El tamano despues de flatten es: ', x.shape)\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        print('El tamano despues de la conv1 es: ', x.shape)\n",
    "        # El tamano despues de la conv1 es:  torch.Size([2, 12, 19])\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        print('El tamano despues de la conv2 es: ', x.shape)\n",
    "        \n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model_S(\n",
       "  (conv1): Conv1d(1, 12, kernel_size=(6,), stride=(2,), padding=(3,))\n",
       "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(26, 14, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model_S(seq_len=seq_len)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ODE_NET(hidden_dim=75)\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tamano de la entrada es:  torch.Size([2, 1, 75])\n",
      "El tamano despues de la conv1 es:  torch.Size([2, 12, 19])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchsummary. See above stack traces for more details. Executed layers up to: [Conv1d: 1-1, MaxPool1d: 1-2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Det-Pc\\anaconda3\\envs\\pytorch-C-DL\\lib\\site-packages\\torchsummary\\torchsummary.py:140\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_data, batch_dim, branching, col_names, col_width, depth, device, dtypes, verbose, *args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 140\u001b[0m         _ \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(device)(\u001b[39m*\u001b[39mx, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Det-Pc\\anaconda3\\envs\\pytorch-C-DL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
      "Cell \u001b[1;32mIn [117], line 23\u001b[0m, in \u001b[0;36mModel_S.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39m# El tamano despues de la conv1 es:  torch.Size([2, 12, 19])\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(x))\n\u001b[0;32m     24\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool2(x)\n",
      "File \u001b[1;32mc:\\Users\\Det-Pc\\anaconda3\\envs\\pytorch-C-DL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1208\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(\u001b[39minput\u001b[39m)\n\u001b[1;32m-> 1208\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1209\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n",
      "File \u001b[1;32mc:\\Users\\Det-Pc\\anaconda3\\envs\\pytorch-C-DL\\lib\\site-packages\\torch\\nn\\modules\\conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\Det-Pc\\anaconda3\\envs\\pytorch-C-DL\\lib\\site-packages\\torch\\nn\\modules\\conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [14, 26, 3], expected input[2, 12, 19] to have 26 channels, but got 12 channels instead",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [120], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchsummary\u001b[39;00m \u001b[39mimport\u001b[39;00m summary\n\u001b[1;32m----> 2\u001b[0m summary(model, (\u001b[39m1\u001b[39;49m,seq_len))\n",
      "File \u001b[1;32mc:\\Users\\Det-Pc\\anaconda3\\envs\\pytorch-C-DL\\lib\\site-packages\\torchsummary\\torchsummary.py:143\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_data, batch_dim, branching, col_names, col_width, depth, device, dtypes, verbose, *args, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    142\u001b[0m     executed_layers \u001b[39m=\u001b[39m [layer \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m summary_list \u001b[39mif\u001b[39;00m layer\u001b[39m.\u001b[39mexecuted]\n\u001b[1;32m--> 143\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    144\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFailed to run torchsummary. See above stack traces for more details. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExecuted layers up to: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(executed_layers)\n\u001b[0;32m    146\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m hooks \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to run torchsummary. See above stack traces for more details. Executed layers up to: [Conv1d: 1-1, MaxPool1d: 1-2]"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (1,seq_len))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('pytorch-C-DL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85b52fbe45fd3d3f6426508f2b1ceb63e7294645d1a7097c9a6e2bd314b42ccf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
